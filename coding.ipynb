{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Medical Diagnosis with CNN& Transfer Learning",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'chest-xray-pneumonia:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F17810%2F23812%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240331%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240331T052036Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D6d5e615149b36f1c12503b4d7d694c8810ae38ad6ca236e4e4102e4e18eca53db3721eeb4425133ee8810bc0e51f43dc4d9aea83edee4609a83120e9c733cbd55c0712984cab94af23003ce935e64f14ea33d231da247f76e68c4839f759e8c4bdc815a29f4477701ca86c78d3502acac8c384442a12427b33a2ccc6a0858b1bf8a2c0aa27ec83be851b05aa6f875e060018c20afa0a5a42a45705bbbab5161365d8a426236ad45ace93b0f144e39fbfd1135d04be492000dba59024373a8ec00c5518b38e8a6f4cef966b8c9d402b1cb18b180ff74f26e8cf71b5370a3a3f199148232fb6a8fcdd65d065e498795e066c701a768dbe7448093feca086c16510'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "H6EwGzAUNgaS"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI for Medical Diagnosis\n",
        "Computer Vision (CV) has a lot of applications in medical diagnosis:\n",
        "\n",
        "* Dermatology\n",
        "* Ophthakmology\n",
        "* Histopathology.\n",
        "\n",
        "X-rays images are critical for the detection of lung cancer, pneumenia ... In this notebook you will learn:\n",
        "\n",
        "* Data pre-processing\n",
        "* Preprocess images properly for the train, validation and test sets.\n",
        "* Set-up a pre-trained neural network to make disease predictions on chest X-rays.\n",
        "\n",
        "In this notebook you will work with chest X-ray images taken from the public ChestX-ray8 dataset."
      ],
      "metadata": {
        "id": "Zhz37-2PNgaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is Pneumonia ?\n",
        "From Mayo Clinic's Article on pneumonia\n",
        "\n",
        "Pneumonia is an infection that inflames the air sacs in one or both lungs. The air sacs may fill with fluid or pus (purulent material), causing cough with phlegm or pus, fever, chills, and difficulty breathing. A variety of organisms, including bacteria, viruses and fungi, can cause pneumonia.\n",
        "\n",
        "Pneumonia can range in seriousness from mild to life-threatening. It is most serious for infants and young children, people older than age 65, and people with health problems or weakened immune systems.\n",
        "\n",
        "![download.png](attachment:download.png)"
      ],
      "metadata": {
        "id": "rOmF3P64NgaZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computer Vision\n",
        "\n",
        "\n",
        "Computer vision is an interdisciplinary scientific field that deals with how computers can gain a high-level understanding from digital images or videos. From the perspective of engineering, it seeks to understand and automate tasks that the human visual system can do.\n",
        "We can use Computer Vision to determine whether a person is affected by pneumonia or not."
      ],
      "metadata": {
        "id": "HeY8Po9VNgaa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pneumonia Detection with Convolutional Neural Networks\n",
        "Computer Vision can be realized using Convolutional neural networks (CNN) They are neural networks making features extraction over an image before classifying it. The feature extraction performed consists of three basic operations:\n",
        "\n",
        "* Filter an image for a particular feature (convolution)\n",
        "* Detect that feature within the filtered image (using the ReLU activation)\n",
        "* Condense the image to enhance the features (maximum pooling)\n",
        "\n",
        "# The convolution process is illustrated below\n",
        "\n",
        "![download.png](attachment:download.png)\n",
        "\n",
        "Using convolution filters with different dimensions or values results in differents features extracted\n",
        "\n",
        "Features are then detected using the reLu activation on each destination pixel.\n",
        "\n",
        "![download1.png](attachment:download1.png)\n",
        "\n",
        "Features are the enhanced with MaxPool layers\n",
        "![download2.png](attachment:download2.png)\n",
        "\n",
        "The stride parameters determines the distance between each filters. The padding one determines if we ignore the borderline pixels or not (adding zeros helps the neural network to get information on the border)\n",
        "\n",
        "![download3.png](attachment:download3.png)\n",
        "\n",
        "The outputs are then concatened in Dense layers\n",
        "\n",
        "![download4.png](attachment:download4.png)\n",
        "\n",
        "By using a sigmoid activation, the neural network determines which class the image belongs to\n",
        "![download5.png](attachment:download5.png)"
      ],
      "metadata": {
        "id": "jvt3dOd8Ngaa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Import Packages and Functions\n",
        "We'll make use of the following packages:\n",
        "\n",
        "* numpy and pandas is what we'll use to manipulate our data\n",
        "* matplotlib.pyplot and seaborn will be used to produce plots for visualization\n",
        "* util will provide the locally defined utility functions that have been provided for this assignment\n",
        "We will also use several modules from the keras framework for building deep learning models.\n",
        "\n",
        "Run the next cell to import all the necessary packages.\n",
        "\n"
      ],
      "metadata": {
        "id": "J04WSTlvNgaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "os.listdir(\"../input/chest-xray-pneumonia/chest_xray\")"
      ],
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "mmIV1SwCNgab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir(\"../input/chest-xray-pneumonia/chest_xray/train/PNEUMONIA\"))"
      ],
      "metadata": {
        "trusted": true,
        "id": "h8G2QVWxNgab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is divided into three sets: 1) Train set 2) Validation set and 3) Test set."
      ],
      "metadata": {
        "id": "V2KYW74nNgac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization\n"
      ],
      "metadata": {
        "id": "sfnFMSwDNgac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"../input/chest-xray-pneumonia/chest_xray/train\"\n",
        "test_dir = \"../input/chest-xray-pneumonia/chest_xray/test\"\n",
        "val_dir = \"../input/chest-xray-pneumonia/chest_xray/val\"\n",
        "\n",
        "print(\"Train set:\\n========================================\")\n",
        "num_pneumonia = len(os.listdir(os.path.join(train_dir, 'PNEUMONIA')))\n",
        "num_normal = len(os.listdir(os.path.join(train_dir, 'NORMAL')))\n",
        "print(f\"PNEUMONIA={num_pneumonia}\")\n",
        "print(f\"NORMAL={num_normal}\")\n",
        "\n",
        "print(\"Test set:\\n========================================\")\n",
        "print(f\"PNEUMONIA={len(os.listdir(os.path.join(test_dir, 'PNEUMONIA')))}\")\n",
        "print(f\"NORMAL={len(os.listdir(os.path.join(test_dir, 'NORMAL')))}\")\n",
        "\n",
        "print(\"Validation set:\\n========================================\")\n",
        "print(f\"PNEUMONIA={len(os.listdir(os.path.join(val_dir, 'PNEUMONIA')))}\")\n",
        "print(f\"NORMAL={len(os.listdir(os.path.join(val_dir, 'NORMAL')))}\")\n",
        "\n",
        "pneumonia = os.listdir(\"../input/chest-xray-pneumonia/chest_xray/train/PNEUMONIA\")\n",
        "pneumonia_dir = \"../input/chest-xray-pneumonia/chest_xray/train/PNEUMONIA\"\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    img = plt.imread(os.path.join(pneumonia_dir, pneumonia[i]))\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "trusted": true,
        "id": "0AdDb7czNgac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal = os.listdir(\"../input/chest-xray-pneumonia/chest_xray/train/NORMAL\")\n",
        "normal_dir = \"../input/chest-xray-pneumonia/chest_xray/train/NORMAL\"\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    img = plt.imread(os.path.join(normal_dir, normal[i]))\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "trusted": true,
        "id": "gzr-wA6BNgac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_img = os.listdir(\"../input/chest-xray-pneumonia/chest_xray/train/NORMAL\")[0]\n",
        "normal_dir = \"../input/chest-xray-pneumonia/chest_xray/train/NORMAL\"\n",
        "sample_img = plt.imread(os.path.join(normal_dir, normal_img))\n",
        "plt.imshow(sample_img, cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.title('Raw Chest X Ray Image')\n",
        "\n",
        "print(f\"The dimensions of the image are {sample_img.shape[0]} pixels width and {sample_img.shape[1]} pixels height, one single color channel.\")\n",
        "print(f\"The maximum pixel value is {sample_img.max():.4f} and the minimum is {sample_img.min():.4f}\")\n",
        "print(f\"The mean value of the pixels is {sample_img.mean():.4f} and the standard deviation is {sample_img.std():.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "rPKbE7gqNgad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ivestigate pixel value distribution"
      ],
      "metadata": {
        "id": "z5R3TEloNgad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(sample_img.ravel(),\n",
        "            label=f\"Pixel Mean {np.mean(sample_img):.4f} & Standard Deviation {np.std(sample_img):.4f}\", kde=False)\n",
        "plt.legend(loc='upper center')\n",
        "plt.title('Distribution of Pixel Intensities in the Image')\n",
        "plt.xlabel('Pixel Intensity')\n",
        "plt.ylabel('# Pixels in Image')"
      ],
      "metadata": {
        "trusted": true,
        "id": "0tSHhNIlNgad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Image Preprocessing\n",
        "Before training, we'll first modify your images to be better suited for training a convolutional neural network. For this task we'll use the Keras ImageDataGenerator function to perform data preprocessing and data augmentation.\n",
        "\n",
        "This class also provides support for basic data augmentation such as random horizontal flipping of images.\n",
        "We also use the generator to transform the values in each batch so that their mean is 0 and their standard deviation is 1 (this will faciliate model training by standardizing the input distribution).\n",
        "The generator also converts our single channel X-ray images (gray-scale) to a three-channel format by repeating the values in the image across all channels (we will want this because the pre-trained model that we'll use requires three-channel inputs)."
      ],
      "metadata": {
        "id": "3TbduinrNgad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "image_generator = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    samplewise_center=True,\n",
        "    samplewise_std_normalization=True\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "dghOCgP_Ngad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a separate generator fo valid and test sets\n",
        "\n",
        "Now we need to build a new generator for validation and t esting data.\n",
        "\n",
        "Why can't use the same generator as for the training data?\n",
        "\n",
        "Look back at the generator we wrote for the training data.\n",
        "\n",
        "It normalizes each image per batch, meaning thatit uses batch statistics.\n",
        "We should not do this with the test and validation data, since in a real life scenario we don't process incoming images a batch at a time (we process one image at a time).\n",
        "Knowing the average per batch of test data would effectively give our model an advantage (The model should not have any information about the test data).\n",
        "What we need to do is to normalize incomming test data using the statistics computed from the training set."
      ],
      "metadata": {
        "id": "fjlEzWOzNgad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = image_generator.flow_from_directory(train_dir,\n",
        "                                            batch_size=8,\n",
        "                                            shuffle=True,\n",
        "                                            class_mode='binary',\n",
        "                                            target_size=(180, 180))\n",
        "\n",
        "validation = image_generator.flow_from_directory(val_dir,\n",
        "                                                batch_size=1,\n",
        "                                                shuffle=False,\n",
        "                                                class_mode='binary',\n",
        "                                                target_size=(180, 180))\n",
        "\n",
        "test = image_generator.flow_from_directory(test_dir,\n",
        "                                            batch_size=1,\n",
        "                                            shuffle=False,\n",
        "                                            class_mode='binary',\n",
        "                                            target_size=(180, 180))"
      ],
      "metadata": {
        "trusted": true,
        "id": "HFJdGcwaNgae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style('white')\n",
        "generated_image, label = train.__getitem__(0)\n",
        "plt.imshow(generated_image[0], cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.title('Raw Chest X Ray Image')\n",
        "\n",
        "print(f\"The dimensions of the image are {generated_image.shape[1]} pixels width and {generated_image.shape[2]} pixels height, one single color channel.\")\n",
        "print(f\"The maximum pixel value is {generated_image.max():.4f} and the minimum is {generated_image.min():.4f}\")\n",
        "print(f\"The mean value of the pixels is {generated_image.mean():.4f} and the standard deviation is {generated_image.std():.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "S3W6ttegNgae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(generated_image.ravel(),\n",
        "            label=f\"Pixel Mean {np.mean(generated_image):.4f} & Standard Deviation {np.std(generated_image):.4f}\", kde=False)\n",
        "plt.legend(loc='upper center')\n",
        "plt.title('Distribution of Pixel Intensities in the Image')\n",
        "plt.xlabel('Pixel Intensity')\n",
        "plt.ylabel('# Pixels in Image')"
      ],
      "metadata": {
        "trusted": true,
        "id": "pDESVqcyNgae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building a CNN model\n",
        "\n",
        "## Impact of imbalance data on loss function\n",
        "\n",
        "Loss Function:\n",
        "$$\\mathcal{L}_{cross-entropy}(x_i) = -(y_i \\log(f(x_i)) + (1-y_i) \\log(1-f(x_i))),$$\n",
        "\n",
        "We can rewrite the the overall average cross-entropy loss over the entire training set `D` of size `N` as follows:\n",
        "$$\\mathcal{L}_{cross-entropy}(\\mathcal{D}) = - \\frac{1}{N}\\big( \\sum_{\\text{positive examples}} \\log (f(x_i)) + \\sum_{\\text{negative examples}} \\log(1-f(x_i)) \\big).$$\n",
        "\n",
        "\n",
        "\n",
        "When we have an imbalance data, using a normal loss function will result a model that bias toward the dominating class. One solution is to use a weighted loss function. Using weighted loss function will balance the contribution in the loss function.\n",
        "\n",
        "$$\\mathcal{L}_{cross-entropy}^{w}(x) = - (w_{p} y \\log(f(x)) + w_{n}(1-y) \\log( 1 - f(x) ) ).$$"
      ],
      "metadata": {
        "id": "ldkkjUhrNgae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Class weights\n",
        "\n",
        "weight_for_0 = num_pneumonia / (num_normal + num_pneumonia)\n",
        "weight_for_1 = num_normal / (num_normal + num_pneumonia)\n",
        "\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "print(f\"Weight for class 0: {weight_for_0:.2f}\")\n",
        "print(f\"Weight for class 1: {weight_for_1:.2f}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "rGoeDE26Ngae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten, BatchNormalization\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(180, 180, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(180, 180, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "l0lkh5xxNgae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Z9uttuGFNgae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = model.fit(\n",
        "    train,\n",
        "    epochs=10,\n",
        "    validation_data=validation,\n",
        "    class_weight=class_weight,\n",
        "    steps_per_epoch=100,\n",
        "    validation_steps=25,\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "fYFhepiTNgaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(r.history['loss'], label='Loss')\n",
        "plt.plot(r.history['val_loss'], label='Val_Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss Evolution')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(r.history['accuracy'], label='Accuracy')\n",
        "plt.plot(r.history['val_accuracy'], label='Val_Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy Evolution')"
      ],
      "metadata": {
        "trusted": true,
        "id": "46VR1TrhNgaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = model.evaluate(test)\n",
        "print(f\"Test Accuracy: {evaluation[1] * 100:.2f}%\")\n",
        "\n",
        "evaluation = model.evaluate(train)\n",
        "print(f\"Train Accuracy: {evaluation[1] * 100:.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "fo0AbbuGNgaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "pred = model.predict(test)\n",
        "\n",
        "print(confusion_matrix(test.classes, pred > 0.5))\n",
        "pd.DataFrame(classification_report(test.classes, pred > 0.5, output_dict=True))"
      ],
      "metadata": {
        "trusted": true,
        "id": "v8RA6Q57Ngaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(test.classes, pred > 0.7))\n",
        "pd.DataFrame(classification_report(test.classes, pred > 0.7, output_dict=True))"
      ],
      "metadata": {
        "trusted": true,
        "id": "Ww5wEDTZNgaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning\n",
        "# DenseNet\n",
        "Densenet is a convolutional network where each layer is connected to all other layers that are deeper in the network:\n",
        "\n",
        "* The first layer is connected to the 2nd, 3rd, 4th etc.\n",
        "* The second layer is conected to the 3rd, 4th, 5th etc.\n",
        "\n",
        "![download.png](attachment:download.png)\n",
        "\n",
        "for more information about the DenseNet Architecture visit this website : https://keras.io/api/applications/densenet/\n"
      ],
      "metadata": {
        "id": "APoC6sX1Ngaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "\n",
        "base_model = DenseNet121(input_shape=(180, 180, 3), include_top=False, weights='imagenet', pooling='avg')\n",
        "\n",
        "base_model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "1V-4uCtlNgaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layers = base_model.layers\n",
        "print(f\"The model has {len(layers)} layers\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "lst8KIZkNgaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The input shape {base_model.input}\")\n",
        "print(f\"The output shape {base_model.output}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "xfM-j8bBNgag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#model = Sequential()\n",
        "base_model = DenseNet121(include_top=False, weights='imagenet')\n",
        "x = base_model.output\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "#model.add(base_model)\n",
        "#model.add(GlobalAveragePooling2D())\n",
        "#model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "trusted": true,
        "id": "6mQ1TGd6Ngag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = model.fit(\n",
        "    train,\n",
        "    epochs=10,\n",
        "    validation_data=validation,\n",
        "    class_weight=class_weight,\n",
        "    steps_per_epoch=100,\n",
        "    validation_steps=25,\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "WSbfVnb0Ngag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(r.history['loss'], label='Loss')\n",
        "plt.plot(r.history['val_loss'], label='Val_Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss Evolution')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(r.history['accuracy'], label='Accuracy')\n",
        "plt.plot(r.history['val_accuracy'], label='Val_Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy Evolution')"
      ],
      "metadata": {
        "trusted": true,
        "id": "aulusHycNgag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = model.evaluate(test)\n",
        "print(f\"Test Accuracy: {evaluation[1] * 100:.2f}%\")\n",
        "\n",
        "evaluation = model.evaluate(train)\n",
        "print(f\"Train Accuracy: {evaluation[1] * 100:.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "dUd36v_DNgag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "JBw7Q4nyNgag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_vals = model.predict(test, steps=len(test))"
      ],
      "metadata": {
        "trusted": true,
        "id": "RHvoOSE2Ngak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(test.classes, predicted_vals > 0.5))\n",
        "pd.DataFrame(classification_report(test.classes, predicted_vals > 0.5, output_dict=True))"
      ],
      "metadata": {
        "trusted": true,
        "id": "ois-hBYRNgak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VGG16\n",
        "Presented in 2014, VGG16 has a very simple and classical architecture, with blocks of 2 or 3 convolutional layers followed by a pooling layer, plus a final dense network composed of 2 hidden layers (of 4096 nodes each) and one output layer (of 1000 nodes). Only 3x3 filters are used.\n",
        "\n",
        "![download7.png](attachment:download7.png)"
      ],
      "metadata": {
        "id": "m0KRcLePNgak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from keras.applications import VGG16\n",
        "\n",
        "\n",
        "vgg16_base_model = VGG16(input_shape=(180,180,3),include_top=False,weights='imagenet')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "smdxhS-fNgak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_base_model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Bad7ANFVNgal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "    vgg16_model = tf.keras.Sequential([\n",
        "        vgg16_base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(512, activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.6),\n",
        "        Dense(128, activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "        Dense(64,activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(1,activation=\"sigmoid\")\n",
        "    ])"
      ],
      "metadata": {
        "trusted": true,
        "id": "1mJgIubRNgal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "    METRICS = [\n",
        "        'accuracy',\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall')\n",
        "    ]\n",
        "    vgg16_model.compile(optimizer=opt,loss='binary_crossentropy',metrics=METRICS)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ceJDdxmlNgal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = vgg16_model.fit(train,\n",
        "          epochs=10,\n",
        "          validation_data=validation,\n",
        "          class_weight=class_weight,\n",
        "          steps_per_epoch=100,\n",
        "          validation_steps=25)\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "rMSpaj6dNgal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(r.history['loss'], label='Loss')\n",
        "plt.plot(r.history['val_loss'], label='Val_Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss Evolution')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(r.history['accuracy'], label='Accuracy')\n",
        "plt.plot(r.history['val_accuracy'], label='Val_Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy Evolution')"
      ],
      "metadata": {
        "trusted": true,
        "id": "vfnj9ZfRNgal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation =vgg16_model.evaluate(test)\n",
        "print(f\"Test Accuracy: {evaluation[1] * 100:.2f}%\")\n",
        "\n",
        "evaluation = vgg16_model.evaluate(train)\n",
        "print(f\"Train Accuracy: {evaluation[1] * 100:.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "1L46aHjYNgal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet\n",
        "\n",
        "See the full explanation and schemes in the Research Paper on Deep Residual Learning (https://arxiv.org/pdf/1512.03385.pdf)"
      ],
      "metadata": {
        "id": "CDShzULgNgal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import ResNet50\n",
        "\n",
        "resnet_base_model = ResNet50(input_shape=(180,180,3), include_top=False, weights='imagenet')\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "HHCOL3GrNgam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_base_model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "MMdIqNInNgam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    resnet_model = tf.keras.Sequential([\n",
        "        resnet_base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(512, activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.6),\n",
        "        Dense(128, activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "        Dense(64,activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(1,activation=\"sigmoid\")\n",
        "    ])\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "    METRICS = [\n",
        "        'accuracy',\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall')\n",
        "    ]\n",
        "    resnet_model.compile(optimizer=opt,loss='binary_crossentropy',metrics=METRICS)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Lga3rzkQNgam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = resnet_model.fit(train,\n",
        "          epochs=10,\n",
        "          validation_data=validation,\n",
        "          class_weight=class_weight,\n",
        "          steps_per_epoch=100,\n",
        "          validation_steps=25)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "NVMm9P1wNgam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(r.history['loss'], label='Loss')\n",
        "plt.plot(r.history['val_loss'], label='Val_Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss Evolution')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(r.history['accuracy'], label='Accuracy')\n",
        "plt.plot(r.history['val_accuracy'], label='Val_Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy Evolution')"
      ],
      "metadata": {
        "trusted": true,
        "id": "bCsf6zUFNgam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation =resnet_model.evaluate(test)\n",
        "print(f\"Test Accuracy: {evaluation[1] * 100:.2f}%\")\n",
        "\n",
        "evaluation = resnet_model.evaluate(train)\n",
        "print(f\"Train Accuracy: {evaluation[1] * 100:.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "lG7enlFKNgan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# InceptionNet\n",
        "Also known as GoogleNet, this architecture presents sub-networks called inception modules, which allows fast training computing, complex patterns detection, and optimal use of parameters\n",
        "\n",
        "for more information visit https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43022.pdf\n",
        "\n"
      ],
      "metadata": {
        "id": "ZHLETf9QNgan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import InceptionV3\n",
        "\n",
        "inception_base_model = InceptionV3(input_shape=(180,180,3),include_top=False,weights='imagenet')\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "IsNzfey4Ngan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    inception_model = tf.keras.Sequential([\n",
        "        inception_base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(512, activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.6),\n",
        "        Dense(128, activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.4),\n",
        "        Dense(64,activation=\"relu\"),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(1,activation=\"sigmoid\")\n",
        "    ])\n",
        "\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "    METRICS = [\n",
        "        'accuracy',\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall')\n",
        "    ]\n",
        "    inception_model.compile(optimizer=opt,loss='binary_crossentropy',metrics=METRICS)"
      ],
      "metadata": {
        "trusted": true,
        "id": "yQ7vCZDWNgan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = inception_model.fit(train,\n",
        "          epochs=10,\n",
        "          validation_data=validation,\n",
        "          class_weight=class_weight,\n",
        "          steps_per_epoch=100,\n",
        "          validation_steps=25)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "sNaV4OdLNgan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(r.history['loss'], label='Loss')\n",
        "plt.plot(r.history['val_loss'], label='Val_Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss Evolution')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(r.history['accuracy'], label='Accuracy')\n",
        "plt.plot(r.history['val_accuracy'], label='Val_Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy Evolution')"
      ],
      "metadata": {
        "trusted": true,
        "id": "pPgr4ISSNgao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation =inception_model.evaluate(test)\n",
        "print(f\"Test Accuracy: {evaluation[1] * 100:.2f}%\")\n",
        "\n",
        "evaluation = inception_model.evaluate(train)\n",
        "print(f\"Train Accuracy: {evaluation[1] * 100:.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "ndeqYKapNgao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "RK2IPmrNNgao"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}